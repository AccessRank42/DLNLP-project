{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3f8df10b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Used for obtaining the training data\n",
        "# ! python ./preprocessing/download_wordvecs.py --download_dir ./data\n",
        "# ! python ./preprocessing/squad_preprocess.py --data_dir ./data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ffe88d2",
      "metadata": {},
      "source": [
        "From the paper:\n",
        "\"We use a max sequence length of 600 during training and a hidden state size of 200 for all recurrent\n",
        "units, maxout layers, and linear layers. All LSTMs have randomly initialized parameters and an\n",
        "initial state of zero. Sentinel vectors are randomly initialized and optimized during training. For\n",
        "the dynamic decoder, we set the maximum number of iterations to 4 and use a maxout pool size of\n",
        "16. We use dropout to regularize our network during training (Srivastava et al., 2014), and optimize\n",
        "the model using ADAM (Kingma & Ba, 2014). All models are implemented and trained with\n",
        "Chainer (Tokui et al., 2015).\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6aba24a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\_environment_check.py:72: UserWarning: \n",
            "--------------------------------------------------------------------------------\n",
            "CuPy (cupy) version 12.3.0 may not be compatible with this version of Chainer.\n",
            "Please consider installing the supported version by running:\n",
            "  $ pip install 'cupy>=7.7.0,<8.0.0'\n",
            "\n",
            "See the following page for more details:\n",
            "  https://docs.cupy.dev/en/latest/install.html\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  warnings.warn(msg.format(\n"
          ]
        }
      ],
      "source": [
        "# %load_ext autoreload\n",
        "\n",
        "# %autoreload 2\n",
        "\n",
        "from model import DynamicCoattentionNW\n",
        "import chainer as ch\n",
        "import numpy as np\n",
        "import chainer.functions as F\n",
        "\n",
        "\n",
        "max_seq_length = 600\n",
        "\n",
        "hid_state_size = 200\n",
        "\n",
        "dyn_dec_max_it = 4\n",
        "maxout_pool_size = 16\n",
        "\n",
        "dropout = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1937fde7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading GLoVE vectors from file: ./data/glove.840B.300d.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2196017/2196017 [01:51<00:00, 19686.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2196018, 300)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from preprocessing.vocab import get_glove\n",
        "\n",
        "glove_path = \"./data/glove.840B.300d.txt\"\n",
        "glove_vector_size = 300\n",
        "emb_mat, word2id, id2word = get_glove(glove_path, glove_vector_size)\n",
        "\n",
        "vocab_size = len(word2id)\n",
        "\n",
        "print(emb_mat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "afff63e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def a_loss_function(prediction, ground_truth):\n",
        "    s_p, e_p = prediction\n",
        "    s_t = ground_truth[:,0].astype('f')\n",
        "    e_t = ground_truth[:,1].astype('f')\n",
        "\n",
        "    start_loss = F.mean_squared_error(s_p.astype('f'), s_t)\n",
        "    end_loss = F.mean_squared_error(e_p.astype('f'), e_t)\n",
        "    total_loss = start_loss + end_loss\n",
        "\n",
        "    if (s_p>e_p).any(): #penalize impossible start > end predictions\n",
        "        total_loss *= 2\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f88519d1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<model.DynamicCoattentionNW at 0x294ece967f0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "model = DynamicCoattentionNW(max_seq_length, hid_state_size, dyn_dec_max_it, maxout_pool_size, dropout, emb_mat)\n",
        "\n",
        "# Setup an optimizer\n",
        "optimizer = ch.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "model.to_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbcac50e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 100/2697.09375 [04:15<1:39:40,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 8.49388102054596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 200/2697.09375 [08:31<1:40:23,  2.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 8.207823593616485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 300/2697.09375 [12:47<1:35:45,  2.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 8.046257079442341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 400/2697.09375 [17:02<1:44:07,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.952217050790787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 500/2697.09375 [20:52<1:20:55,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.895180998802185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 600/2697.09375 [24:50<1:13:57,  2.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.829199256102244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 700/2697.09375 [28:39<1:19:43,  2.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.78052865913936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 800/2697.09375 [32:54<1:18:31,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.7429425102472305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 900/2697.09375 [37:20<1:16:54,  2.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.707712915738424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 1000/2697.09375 [41:34<1:03:48,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.673960052013397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 1100/2697.09375 [45:35<1:06:02,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.6466859605095605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 1200/2697.09375 [49:56<1:01:05,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.620879534482956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 1300/2697.09375 [54:13<1:02:14,  2.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.594574788900522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 1400/2697.09375 [58:32<52:42,  2.44s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.576097026552473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 1500/2697.09375 [1:02:29<46:16,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.557947903633118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1600/2697.09375 [1:06:45<52:24,  2.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.541947692632675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 1700/2697.09375 [1:10:51<40:03,  2.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.5202159760980045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 1800/2697.09375 [1:15:04<35:32,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.489921306504144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1900/2697.09375 [1:19:17<33:52,  2.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.450511437717237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 2000/2697.09375 [1:23:39<28:30,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.395540391921997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 2100/2697.09375 [1:27:41<24:38,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.336952983765375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 2200/2697.09375 [1:31:28<19:36,  2.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.273433798876676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 2300/2697.09375 [1:35:30<15:11,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.210173169218976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 2400/2697.09375 [1:39:27<11:20,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.14447316010793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2500/2697.09375 [1:43:22<08:19,  2.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 7.072308417129516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 2600/2697.09375 [1:47:05<03:59,  2.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean loss: 6.997671268719893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 2696/2697.09375 [1:50:55<00:02,  2.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss of epoch 1: 6.9193424490509825\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 7/2697.09375 [00:17<1:51:56,  2.50s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 54\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# prediction = model(batch.context_ids, batch.qn_ids)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# # Calculate the loss\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# loss = a_loss_function(prediction, ground_truth)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Calculate the gradients in the network\u001b[39;00m\n\u001b[0;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39mcleargrads()\n\u001b[1;32m---> 54\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Update all the trainable parameters\u001b[39;00m\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mupdate()\n",
            "File \u001b[1;32mc:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\variable.py:1581\u001b[0m, in \u001b[0;36mVariable.backward\u001b[1;34m(self, retain_grad, enable_double_backprop, loss_scale)\u001b[0m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m chainer\u001b[38;5;241m.\u001b[39musing_config(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menable_backprop\u001b[39m\u001b[38;5;124m'\u001b[39m, enable_double_backprop):\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;66;03m# TODO(kataoka): The following line should not pass grad_var = None\u001b[39;00m\n\u001b[0;32m   1579\u001b[0m     \u001b[38;5;66;03m# to _backprop_to_all, but it is working because grad_var is\u001b[39;00m\n\u001b[0;32m   1580\u001b[0m     \u001b[38;5;66;03m# immediately popped away as None = _backprop_utils._reduce([None])\u001b[39;00m\n\u001b[1;32m-> 1581\u001b[0m     \u001b[43m_backprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backprop_to_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_var\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_scale\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\_backprop.py:225\u001b[0m, in \u001b[0;36m_backprop_to_all\u001b[1;34m(outputs, retain_grad, loss_scale)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m in_grad:\n\u001b[0;32m    223\u001b[0m         in_grad[x] \u001b[38;5;241m=\u001b[39m grads\u001b[38;5;241m.\u001b[39mget_as_list(x)\n\u001b[1;32m--> 225\u001b[0m \u001b[43m_backprop_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_input_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_debug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n\u001b[0;32m    229\u001b[0m     hook\u001b[38;5;241m.\u001b[39mbackward_postprocess(\n\u001b[0;32m    230\u001b[0m         func, \u001b[38;5;28mtuple\u001b[39m(in_data), \u001b[38;5;28mtuple\u001b[39m(out_grad_array))\n",
            "File \u001b[1;32mc:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\_backprop_utils.py:137\u001b[0m, in \u001b[0;36mbackprop_step\u001b[1;34m(func, target_input_indexes, grad_outputs, grad_inputs, is_debug)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# otherwise, backward should be overridden\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# Call backward()\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m         gxs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_input_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    140\u001b[0m         _reraise_with_stack(func, e)\n",
            "File \u001b[1;32mc:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\functions\\math\\minmax.py:72\u001b[0m, in \u001b[0;36mSelectorBase.backward\u001b[1;34m(self, indexes, gy)\u001b[0m\n\u001b[0;32m     70\u001b[0m cond \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m     71\u001b[0m gy \u001b[38;5;241m=\u001b[39m chainer\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mbroadcast_to(gy, cond\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m,\n",
            "File \u001b[1;32mc:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\functions\\math\\basic_math.py:412\u001b[0m, in \u001b[0;36mmul\u001b[1;34m(self, rhs)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39misscalar(rhs):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MulConstant(rhs)\u001b[38;5;241m.\u001b[39mapply((\u001b[38;5;28mself\u001b[39m,))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 412\u001b[0m rhs \u001b[38;5;241m=\u001b[39m \u001b[43m_preprocess_rhs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Mul()\u001b[38;5;241m.\u001b[39mapply((\u001b[38;5;28mself\u001b[39m, rhs))[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\functions\\math\\basic_math.py:69\u001b[0m, in \u001b[0;36m_preprocess_rhs\u001b[1;34m(x, value)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (numpy\u001b[38;5;241m.\u001b[39misscalar(value)\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, chainer\u001b[38;5;241m.\u001b[39mget_array_types())):\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue must be a scalar, `numpy.ndarray`, `cupy.ndarray` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor a `Variable`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mActual: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(value)))\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from data_batcher import get_batch_generator\n",
        "from chainer.backends import cuda\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# batchsize = 2 # for quick test only\n",
        "batchsize = 32 # seems to be the fastest overall\n",
        "# batchsize = 64\n",
        "max_epoch = 10\n",
        "epochs_pre_trained = 0\n",
        "show_mean_loss_at_batches = 200\n",
        "\n",
        "train_file_lines = 86307\n",
        "\n",
        "train_context_path = \"./data/train.context\"\n",
        "train_qn_path = \"./data/train.question\"\n",
        "train_ans_path = \"./data/train.answer\"\n",
        "train_span_path = \"./data/train.span\"\n",
        "\n",
        "for i in range(max_epoch, 0, -1):\n",
        "    try:\n",
        "        ch.serializers.load_npz('DCANW_E{}.model'.format(i), model)\n",
        "        print(\"Model DCANW_E{}.model loaded successfully\".format(i))\n",
        "        epochs_pre_trained = i\n",
        "        break\n",
        "    except FileNotFoundError:\n",
        "        continue\n",
        "\n",
        "\n",
        "for epoch in range(1+epochs_pre_trained, max_epoch+1):\n",
        "    print(\"Epoch: {}\".format(epoch))\n",
        "    batch_gen = get_batch_generator(word2id, train_context_path, train_qn_path, train_span_path, batchsize, max_seq_length, max_seq_length, discard_long=True)\n",
        "    batch_id = 0\n",
        "    losses = []\n",
        "    for batch in tqdm(batch_gen, total=train_file_lines/batchsize): # progress bar\n",
        "        ch.cuda.cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "        batch_id += 1\n",
        "        model.reset_state()\n",
        "    \n",
        "        # Calculate the prediction of the network\n",
        "        c_seq = ch.Variable(cuda.to_gpu(batch.context_ids))\n",
        "        q_seq = ch.Variable(cuda.to_gpu(batch.qn_ids))\n",
        "        ground_truth = cuda.to_gpu(batch.ans_span)\n",
        "        s_prediction, e_prediction, loss = model(c_seq, q_seq, ground_truth)\n",
        "        # prediction = model(batch.context_ids, batch.qn_ids)\n",
        "\n",
        "        # # Calculate the loss\n",
        "        # loss = a_loss_function(prediction, ground_truth)\n",
        "\n",
        "        # Calculate the gradients in the network\n",
        "        model.cleargrads()\n",
        "        loss.backward()\n",
        "\n",
        "        # Update all the trainable parameters\n",
        "        optimizer.update()\n",
        "\n",
        "        # print(\"Batch done\")\n",
        "        losses.append(loss.item())\n",
        "        if batch_id % show_mean_loss_at_batches == 0:\n",
        "            print(\"Current mean loss of epoch: {}\".format(np.mean(losses)))\n",
        "\n",
        "    print(\"Mean loss of epoch {}: {}\".format(epoch, np.mean(losses)))\n",
        "    ch.serializers.save_npz('DCANW_E{}.model'.format(epoch), model)\n",
        "    \n",
        "\n",
        "\n",
        "print(\"Training for {} epochs finished\".format(max_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a51e162",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "    #  # Display the training loss\n",
        "    #     print('epoch:{} train_loss:{:.04f} '.format(\n",
        "    #         epoch, ))\n",
        "\n",
        "    #     test_losses = []\n",
        "    #     test_accuracies = []\n",
        "    #     for test_batch in test_iter:\n",
        "    #         image_test, target_test = concat_examples(test_batch, gpu_id)\n",
        "\n",
        "    #         # Forward the test data\n",
        "    #         prediction_test = model(image_test)\n",
        "\n",
        "    #         # Calculate the loss\n",
        "    #         loss_test = F.softmax_cross_entropy(prediction_test, target_test)\n",
        "    #         test_losses.append(to_cpu(loss_test.array))\n",
        "\n",
        "    #         # Calculate the accuracy\n",
        "    #         accuracy = F.accuracy(prediction_test, target_test)\n",
        "    #         accuracy.to_cpu()\n",
        "    #         test_accuracies.append(accuracy.array)\n",
        "\n",
        "    #     test_iter.reset()\n",
        "\n",
        "    #     print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
        "    #         np.mean(test_losses), np.mean(test_accuracies)))\n",
        "\n",
        "# # train_iter = ch.iterators.SerialIterator(train, batchsize)\n",
        "# # test_iter = ch.iterators.SerialIterator(test, batchsize, False, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ea519ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Create the updater, using the optimizer --> not used\n",
        "# updater = ch.training.StandardUpdater(train_iter, optimizer, device=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc50999c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Set up a trainer -- not used\n",
        "# max_epoch = 10\n",
        "# trainer = ch.training.Trainer(updater, (max_epoch, 'epoch'), out='result')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DLNLP-Project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
