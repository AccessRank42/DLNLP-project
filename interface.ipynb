{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f8df10b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Used for obtaining the training data\n",
        "# # Uncomment and run for the first-time setup\n",
        "# ! python ./preprocessing/download_wordvecs.py --download_dir ./data\n",
        "# ! python ./preprocessing/squad_preprocess.py --data_dir ./data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f71d3e",
      "metadata": {},
      "source": [
        "Ideas:  check Dropout applied where it should be\n",
        "check EmbId - expected input vs actual input\n",
        "input: padding -> mask needed?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ffe88d2",
      "metadata": {},
      "source": [
        "From the paper:\n",
        "\"We use a max sequence length of 600 during training and a hidden state size of 200 for all recurrent\n",
        "units, maxout layers, and linear layers. All LSTMs have randomly initialized parameters and an\n",
        "initial state of zero. Sentinel vectors are randomly initialized and optimized during training. For\n",
        "the dynamic decoder, we set the maximum number of iterations to 4 and use a maxout pool size of\n",
        "16. We use dropout to regularize our network during training (Srivastava et al., 2014), and optimize\n",
        "the model using ADAM (Kingma & Ba, 2014). All models are implemented and trained with\n",
        "Chainer (Tokui et al., 2015).\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6aba24a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\chainer\\_environment_check.py:72: UserWarning: \n",
            "--------------------------------------------------------------------------------\n",
            "CuPy (cupy) version 12.3.0 may not be compatible with this version of Chainer.\n",
            "Please consider installing the supported version by running:\n",
            "  $ pip install 'cupy>=7.7.0,<8.0.0'\n",
            "\n",
            "See the following page for more details:\n",
            "  https://docs.cupy.dev/en/latest/install.html\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  warnings.warn(msg.format(\n"
          ]
        }
      ],
      "source": [
        "from model import DynamicCoattentionNW\n",
        "import chainer as ch\n",
        "import numpy as np\n",
        "import chainer.functions as F\n",
        "\n",
        "\n",
        "max_seq_length = 600\n",
        "\n",
        "hid_state_size = 200\n",
        "\n",
        "dyn_dec_max_it = 4\n",
        "maxout_pool_size = 16\n",
        "\n",
        "dropout = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1937fde7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading GLoVE vectors from file: ./data/glove.840B.300d.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2196017/2196017 [01:49<00:00, 20011.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2196018, 300)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from preprocessing.vocab import get_glove\n",
        "\n",
        "glove_path = \"./data/glove.840B.300d.txt\"\n",
        "glove_vector_size = 300\n",
        "emb_mat, word2id, id2word = get_glove(glove_path, glove_vector_size)\n",
        "\n",
        "vocab_size = len(word2id)\n",
        "\n",
        "print(emb_mat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f88519d1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<model.DynamicCoattentionNW at 0x253eee64970>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "model = DynamicCoattentionNW(max_seq_length, hid_state_size, dyn_dec_max_it, maxout_pool_size, dropout, emb_mat)\n",
        "\n",
        "# Setup an optimizer\n",
        "optimizer = ch.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "model.to_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fbcac50e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model DCANW_E10.model loaded successfully\n",
            "Training for 10 epochs finished\n"
          ]
        }
      ],
      "source": [
        "from data_batcher import get_batch_generator\n",
        "from chainer.backends import cuda\n",
        "from tqdm import tqdm\n",
        "\n",
        "# batchsize = 2 # for quick test only\n",
        "batchsize = 32 # seems to be the fastest overall\n",
        "# batchsize = 64\n",
        "# max_epoch = 15\n",
        "max_epoch = 10\n",
        "epochs_pre_trained = 0\n",
        "show_mean_loss_at_batches = 200\n",
        "\n",
        "train_file_lines = 86300 # rougly\n",
        "\n",
        "train_context_path = \"./data/train.context\"\n",
        "train_qn_path = \"./data/train.question\"\n",
        "train_ans_path = \"./data/train.answer\"\n",
        "train_span_path = \"./data/train.span\"\n",
        "\n",
        "# try loading a trained model\n",
        "for i in range(max_epoch, 0, -1):\n",
        "    try:\n",
        "        ch.serializers.load_npz('DCANW_E{}.model'.format(i), model)\n",
        "        print(\"Model DCANW_E{}.model loaded successfully\".format(i))\n",
        "        epochs_pre_trained = i\n",
        "        break\n",
        "    except FileNotFoundError:\n",
        "        continue\n",
        "\n",
        "\n",
        "for epoch in range(1+epochs_pre_trained, max_epoch+1):\n",
        "    print(\"Epoch: {}\".format(epoch))\n",
        "    batch_gen = get_batch_generator(word2id, train_context_path, train_qn_path, train_span_path, batchsize, max_seq_length, max_seq_length, discard_long=True)\n",
        "    batch_id = 0\n",
        "    losses = []\n",
        "    for batch in tqdm(batch_gen, total=train_file_lines/batchsize): # progress bar\n",
        "        ch.cuda.cupy.get_default_pinned_memory_pool().free_all_blocks() #free up memory\n",
        "        batch_id += 1\n",
        "        model.reset_state()\n",
        "    \n",
        "        # Calculate the prediction & loss of the network\n",
        "        c_seq = ch.Variable(cuda.to_gpu(batch.context_ids))\n",
        "        q_seq = ch.Variable(cuda.to_gpu(batch.qn_ids))\n",
        "        ground_truth = cuda.to_gpu(batch.ans_span)\n",
        "        s_prediction, e_prediction, loss = model(c_seq, q_seq, ground_truth)\n",
        "\n",
        "        # Calculate the gradients in the network\n",
        "        model.cleargrads()\n",
        "        loss.backward()\n",
        "\n",
        "        # Update all the trainable parameters\n",
        "        optimizer.update()\n",
        "\n",
        "        # print(\"Batch done\")\n",
        "        losses.append(loss.item())\n",
        "        if batch_id % show_mean_loss_at_batches == 0:\n",
        "            print(\"Current mean loss of epoch: {}\".format(np.mean(losses)))\n",
        "\n",
        "    print(\"Mean loss of epoch {}: {}\".format(epoch, np.mean(losses)))\n",
        "    print(\"Last loss of epoch {}: {}\".format(epoch, losses[-1]))\n",
        "    ch.serializers.save_npz('DCANW_E{}.model'.format(epoch), model)\n",
        "    \n",
        "\n",
        "\n",
        "print(\"Training for {} epochs finished\".format(max_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d6834b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 321/321.875 [02:05<00:00,  2.65it/s]c:\\Users\\temp\\anaconda3\\envs\\DLNLP-Project\\lib\\site-packages\\tqdm\\std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
            "  full_bar = Bar(frac,\n",
            "325it [02:06,  2.56it/s]                             \n"
          ]
        }
      ],
      "source": [
        "# quick and dirty evaluation\n",
        "batchsize = 32 # seems to be the fastest overall\n",
        "# batchsize = 4\n",
        "# batchsize = 64\n",
        "\n",
        "dev_file_lines = 10400 # rougly\n",
        "\n",
        "dev_context_path = \"./data/dev.context\"\n",
        "dev_qn_path = \"./data/dev.question\"\n",
        "dev_ans_path = \"./data/dev.answer\"\n",
        "dev_span_path = \"./data/dev.span\"\n",
        "\n",
        "batch_gen = get_batch_generator(word2id, dev_context_path, dev_qn_path, dev_span_path, batchsize, max_seq_length, max_seq_length, discard_long=True)\n",
        "\n",
        "with open(\"log.txt\", \"w\") as file:\n",
        "    with ch.using_config('train', False):\n",
        "        for batch in tqdm(batch_gen, total=dev_file_lines/batchsize): # progress bar\n",
        "            ch.cuda.cupy.get_default_pinned_memory_pool().free_all_blocks() #free up memory\n",
        "            model.reset_state()\n",
        "\n",
        "            # Calculate the prediction\n",
        "            c_seq = ch.Variable(cuda.to_gpu(batch.context_ids))\n",
        "            q_seq = ch.Variable(cuda.to_gpu(batch.qn_ids))\n",
        "            ground_truth = cuda.to_gpu(batch.ans_span)\n",
        "            s_prediction, e_prediction, _ = model(c_seq, q_seq, ground_truth)\n",
        "\n",
        "            for j in range(len(s_prediction)):\n",
        "                file.write(\"\\nContext: \")\n",
        "                file.write(str(\" \".join(batch.context_tokens[j])))\n",
        "\n",
        "                file.write(\"\\nQuestion: \")\n",
        "                file.write(str(\" \".join(batch.qn_tokens[j])))\n",
        "\n",
        "                file.write(\"\\nAnswer: \")\n",
        "                file.write(str(\" \".join(batch.ans_tokens[j])))\n",
        "                # file.write(str(batch.ans_span))\n",
        "            \n",
        "                file.write(\"\\nPrediction: \")\n",
        "                file.write(str(\" \".join(batch.context_tokens[j][int(s_prediction[j]):int(e_prediction[j])+1])))\n",
        "                file.write(\"\\n\")\n",
        "                # file.write(str([[int(s_prediction[i]), int(e_prediction[i])] for i in range(len(s_prediction))]))\n",
        "\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DLNLP-Project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
